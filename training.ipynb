{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "burning-mathematics",
   "metadata": {},
   "source": [
    "## Clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proud-definition",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b5081526cfb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \"\"\"\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_device_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_CudaDeviceProperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will define _get_device_properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "steady-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: .: file changed as we read it\r\n"
     ]
    }
   ],
   "source": [
    "!tar -czf - ./ | split --bytes=100MB - ./workspaces.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forty-manual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "%cd jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interior-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "!trash-empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stuffed-thunder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'myolov5'...\n",
      "Username for 'https://github.com': ^C\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/GiuliaCiaramella/myolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "lasting-image",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to a new branch 'virtual-machine'\r\n"
     ]
    }
   ],
   "source": [
    "!git checkout -b virtual-machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "frozen-solid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 0 (delta 0), reused 0 (delta 0)\n",
      "remote: \n",
      "remote: Create a pull request for 'virtual-machine' on GitHub by visiting:\u001b[K\n",
      "remote:      https://github.com/GiuliaCiaramella/myolov5/pull/new/virtual-machine\u001b[K\n",
      "remote: \n",
      "To https://github.com/GiuliaCiaramella/myolov5.git\n",
      " * [new branch]      virtual-machine -> virtual-machine\n"
     ]
    }
   ],
   "source": [
    "!git push origin virtual-machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "tired-trace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /home)\r\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\r\n"
     ]
    }
   ],
   "source": [
    "!git add *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "exciting-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETECTION.ipynb  myolov5\t     src\t     wandb\r\n",
      "io.jpg\t\t old_training.ipynb  training.ipynb  yolov5\r\n",
      "io_saved.jpg\t requirements.txt    tutorials\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "unable-morris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/myolov5\n"
     ]
    }
   ],
   "source": [
    "%cd myolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-independence",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q wandb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ufoym/imbalanced-dataset-sampler\n",
    "%cd imbalanced-dataset-sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-emperor",
   "metadata": {},
   "source": [
    "## Giulia API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#WANDB_API_KEY= 'b9ce0ac37518ed3979101e8a8eeaf27fc3a13139'\n",
    "#os.environ['WANDB_API_KEY'] = WANDB_API_KEY \n",
    "#API key Giulia\n",
    "#!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-vietnamese",
   "metadata": {},
   "source": [
    "## Kutay API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "resistant-sleep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkutay\u001b[0m (use `wandb login --relogin` to force relogin)\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "WANDB_API_KEY= 'd4cea02e3fa0374fa24e619598b5cbff8aa02f53' \n",
    "os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n",
    "#API key Kutay\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naughty-deadline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/yolov5\n",
      "02_2nozzles.mp4\t\t       metrics.csv\r\n",
      "079_0056.MOV\t\t       metrics_new.csv\r\n",
      "079_0056_cut_10.MOV\t       metrics_previous.csv\r\n",
      "2e_64b_s_not_frz_coco_640img4  models\r\n",
      "Dockerfile\t\t       my_original.png\r\n",
      "LICENSE\t\t\t       project.csv\r\n",
      "README.md\t\t       requirements.txt\r\n",
      "_2021-04-12-11h-02m-30s.txt    runs\r\n",
      "__pycache__\t\t       storage_tank_colab.yaml\r\n",
      "autoevaluate.py\t\t       test.py\r\n",
      "data\t\t\t       test_data\r\n",
      "detect.py\t\t       train.py\r\n",
      "detect_my_1.py\t\t       tutorial.ipynb\r\n",
      "detect_my_colab.py\t       utils\r\n",
      "feat_vectors_Xception.txt      utils_obj\r\n",
      "general_conf.yaml\t       wandb\r\n",
      "hubconf.py\t\t       weights\r\n",
      "imbalanced-dataset-sampler     who_wrote_this.csv\r\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aware-oriental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/yolov5\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "north-helicopter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ WARNING: code is out of date by 53 commits. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n",
      "YOLOv5 🚀 v4.0-150-g1620669 torch 1.7.1 CPU\n",
      "\n",
      "Namespace(adam=False, artifact_alias='latest', batch_size=2, bbox_interval=-1, bucket='', cache_images=True, cfg='models/yolov5s.yaml', data='test_data/data.yaml', device='', entity=None, epochs=2, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], linear_lr=False, local_rank=-1, multi_scale=False, name='2e_2b_s_not_frz_coco_640img', noautoanchor=False, nosave=True, notest=False, project='runs/train/test_data', quad=False, rect=False, resume=False, save_dir='runs/train/test_data/2e_2b_s_not_frz_coco_640img2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=2, upload_dataset=False, weights='weights/yolov5s.pt', workers=8, world_size=1)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train/test_data', view at http://localhost:6006/\n",
      "2021-04-14 09:38:12.661664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkutay\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.26 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-04-14 09:38:20.185779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.23\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m2e_2b_s_not_frz_coco_640img2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/kutay/test_data\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/kutay/test_data/runs/xh47q3cs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/jupyter/yolov5/wandb/run-20210414_093819-xh47q3cs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7071633 parameters, 7071633 gradients, 16.4 GFLOPS\n",
      "\n",
      "Transferred 354/362 items from weights/yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 62 .bias, 62 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'test_data/train/labels.cache' images and labels... 1827 found, 0 missing, 8 empty, 0 corrupted: 100%|██████████| 1827/1827 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.2GB): 100%|██████████| 1827/1827 [00:04<00:00, 446.33it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'test_data/valid/labels.cache' images and labels... 174 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 174/174 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB):  58%|█████▊    | 101/174 [00:00<00:00, 349.78it/s]^C\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.2GB):  81%|████████  | 141/174 [00:00<00:00, 352.47it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 733, in next\n",
      "    item = self._items.popleft()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 562, in <module>\n",
      "    train(hyp, opt, device, tb_writer)\n",
      "  File \"train.py\", line 214, in train\n",
      "    pad=0.5, prefix=colorstr('val: '))[0]\n",
      "  File \"/home/jupyter/yolov5/utils/datasets.py\", line 74, in create_dataloader\n",
      "    prefix=prefix)\n",
      "  File \"/home/jupyter/yolov5/utils/datasets.py\", line 444, in __init__\n",
      "    for i, x in pbar:\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tqdm/std.py\", line 1176, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 737, in next\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 296, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255.  Press ctrl-c to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "yolo_version = 's'\n",
    "#epochs = 250\n",
    "epochs = 2\n",
    "batches= 2\n",
    "#batches= 16\n",
    "#yaml= 'overhead_cranes/data.yaml'\n",
    "#project = 'runs/train/overhead_cranes'\n",
    "#model = 'models/yolov5'+yolo_version+'.yaml'\n",
    "\n",
    "#yaml= 'storage_tank_new/data.yaml'\n",
    "#project = 'runs/train/storage_tank_new'\n",
    "#model = 'models/yolov5'+yolo_version+'.yaml'\n",
    "\n",
    "\n",
    "\n",
    "yaml= 'test_data/data.yaml'\n",
    "project = 'runs/train/test_data'\n",
    "model = 'models/yolov5'+yolo_version+'.yaml'\n",
    "\n",
    "which_weights = 'coco' # coco, cust or our best\n",
    "freez = 'false'\n",
    "#img_size = 416\n",
    "img_size = 640\n",
    "\n",
    "if freez == 'true':\n",
    "    freez_name = 'frz'\n",
    "elif freez == 'false':\n",
    "    freez_name = 'not_frz'\n",
    "\n",
    "#freeze = ['model.%s.' % x for x in range(10)]\n",
    "\n",
    "if which_weights == 'st':\n",
    "    weights='runs/train/st_modified/250e_16b_s_not_frz_coco_640img/weights/last.pt' # our best weights must be moved here\n",
    "elif which_weights == 'coco':\n",
    "    weights = 'weights/yolov5'+yolo_version+'.pt' # yolov5s.pt\n",
    "elif which_weights == 'cust':\n",
    "    weights = 'runs/train/st_modified/'+str(epochs)+'e_'+str(batches)+'b_'+yolo_version+'_'+str(img_size)+'img/weights/last.pt'\n",
    "    #weights = 'runs/train/storage_tank_2/'+str(epochs)+'e_'+str(batches)+'b_'+yolo_version+'/weights/last.pt'\n",
    "\n",
    "name=str(epochs)+'e_'+str(batches)+'b_'+yolo_version+'_'+freez_name+'_'+which_weights+'_'+str(img_size)+'img'\n",
    "\n",
    "# include  --evolve in the command if you want to do hyperparameters evolution --> takes hundreds of hours\n",
    "#original train command\n",
    "\n",
    "\n",
    "!python train.py --img-size {img_size} --batch {batches} --epochs {epochs} --data {yaml} --cfg {model} --weights {weights} --nosave --cache --project {project} --name {name}\n",
    "#!python train.py --img-size {img_size} --batch {batches} --epochs {epochs} --data {yaml} --cfg {model} --weights '' --nosave --cache --project {project} --freezing {freez} --name {name}\n",
    "#!python train.py --img-size {img_size} --batch {batches} --epochs {epochs} --data {yaml} --cfg {model} --weights {weights} --nosave --project {project} --freezing {freez} --name {name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "northern-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoevaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hydraulic-position",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use new model because new model's acurracy and its curve is better\n"
     ]
    }
   ],
   "source": [
    "autoeval(\"/home/jupyter/yolov5/metrics_new.csv\",\"/home/jupyter/yolov5/metrics_previous.csv\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
